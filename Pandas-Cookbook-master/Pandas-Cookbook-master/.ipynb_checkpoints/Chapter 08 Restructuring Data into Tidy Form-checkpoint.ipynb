{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8: Restructuring Data into Tidy Form\n",
    "## Recipes\n",
    "* [Tidying variable values as column names with stack](#Tidying-variable-values-as-column-names-with-stack)\n",
    "* [Tidying variable values as column names with melt](#Tidying-variable-values-as-column-names-with-melt)\n",
    "* [Stacking multiple groups of variables simultaneously](#Stacking-multiple-groups-of-variables-simultaneously)\n",
    "* [Inverting stacked data](#Inverting-stacked-data)\n",
    "* [Unstacking after a groupby aggregation](#Unstacking-after-a-groupby-aggregation)\n",
    "* [Replicating pivot_table with a groupby aggregation](#Replicating-pivot_table-with-a-groupby-aggregation)\n",
    "* [Renaming axis levels for easy reshaping](#Renaming-axis-levels-for-easy-reshaping)\n",
    "* [Tidying when multiple variables are stored as column names](#Tidying-when-multiple-variables-are-stored-as-column-names)\n",
    "* [Tidying when multiple variables are stored as column values](#Tidying-when-multiple-variables-are-stored-as-column-values)\n",
    "* [Tidying when two or more values are stored in the same cell](#Tidying-when-two-or-more-values-are-stored-in-the-same-cell)\n",
    "* [Tidying when variables are stored in column names and values](#Tidying-when-variables-are-stored-in-column-names-and-values)\n",
    "* [Tidying when multiple observational units are stored in the same table](#Tidying-when-multiple-observational-units-are-stored-in-the-same-table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidying variable values as column names with stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fruit = pd.read_csv('data/state_fruit.csv', index_col=0)\n",
    "state_fruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fruit.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fruit_tidy = state_fruit.stack().reset_index()\n",
    "state_fruit_tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fruit_tidy.columns = ['state', 'fruit', 'weight']\n",
    "state_fruit_tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fruit.stack()\\\n",
    "           .rename_axis(['state', 'fruit'])\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fruit.stack()\\\n",
    "           .rename_axis(['state', 'fruit'])\\\n",
    "           .reset_index(name='weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There's more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fruit2 = pd.read_csv('data/state_fruit2.csv')\n",
    "state_fruit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fruit2.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fruit2.set_index('State').stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidying variable values as column names with melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fruit2 = pd.read_csv('data/state_fruit2.csv')\n",
    "state_fruit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fruit2.melt(id_vars=['State'],\n",
    "                 value_vars=['Apple', 'Orange', 'Banana'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fruit2.index=list('abc')\n",
    "state_fruit2.index.name = 'letter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fruit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fruit2.melt(id_vars=['State'],\n",
    "                 value_vars=['Apple', 'Orange', 'Banana'],\n",
    "                 var_name='Fruit',\n",
    "                 value_name='Weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There's more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fruit2.melt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fruit2.melt(id_vars='State')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking multiple groups of variables simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv('data/movie.csv')\n",
    "actor = movie[['movie_title', 'actor_1_name', 'actor_2_name', 'actor_3_name', \n",
    "               'actor_1_facebook_likes', 'actor_2_facebook_likes', 'actor_3_facebook_likes']]\n",
    "actor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_col_name(col_name):\n",
    "    col_name = col_name.replace('_name', '')\n",
    "    if 'facebook' in col_name:\n",
    "        fb_idx = col_name.find('facebook')\n",
    "        col_name = col_name[:5] + col_name[fb_idx - 1:] + col_name[5:fb_idx-1]\n",
    "    return col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor2 = actor.rename(columns=change_col_name)\n",
    "actor2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stubs = ['actor', 'actor_facebook_likes']\n",
    "actor2_tidy = pd.wide_to_long(actor2, \n",
    "                              stubnames=stubs, \n",
    "                              i=['movie_title'], \n",
    "                              j='actor_num', \n",
    "                              sep='_').reset_index()\n",
    "actor2_tidy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There's more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/stackme.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.rename(columns = {'a1':'group1_a1', 'b2':'group1_b2',\n",
    "                           'd':'group2_a1', 'e':'group2_b2'})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.wide_to_long(df2, \n",
    "                stubnames=['group1', 'group2'], \n",
    "                i=['State', 'Country', 'Test'], \n",
    "                j='Label', \n",
    "                suffix='.+', \n",
    "                sep='_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Inverting stacked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecol_func = lambda x: 'UGDS_' in x or x == 'INSTNM'\n",
    "college = pd.read_csv('data/college.csv', \n",
    "                          index_col='INSTNM', \n",
    "                          usecols=usecol_func)\n",
    "college.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_stacked = college.stack()\n",
    "college_stacked.head(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_stacked.unstack().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college2 = pd.read_csv('data/college.csv', \n",
    "                      usecols=usecol_func)\n",
    "college2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_melted = college2.melt(id_vars='INSTNM', \n",
    "                               var_name='Race',\n",
    "                               value_name='Percentage')\n",
    "college_melted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_inv = college_melted.pivot(index='INSTNM',\n",
    "                                  columns='Race',\n",
    "                                  values='Percentage')\n",
    "melted_inv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college2_replication = melted_inv.loc[college2['INSTNM'], \n",
    "                                      college2.columns[1:]]\\\n",
    "                                         .reset_index()\n",
    "college2.equals(college2_replication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There's more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.stack().unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unstacking after a groupby aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee = pd.read_csv('data/employee.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee.groupby('RACE')['BASE_SALARY'].mean().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = employee.groupby(['RACE', 'GENDER'])['BASE_SALARY'].mean().astype(int)\n",
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg.unstack('GENDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg.unstack('RACE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There's more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg2 = employee.groupby(['RACE', 'GENDER'])['BASE_SALARY'].agg(['mean', 'max', 'min']).astype(int)\n",
    "agg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicating pivot_table with a groupby aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.read_csv('data/flights.csv')\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = flights.pivot_table(index='AIRLINE', \n",
    "                         columns='ORG_AIR', \n",
    "                         values='CANCELLED', \n",
    "                         aggfunc='sum',\n",
    "                         fill_value=0).round(2)\n",
    "fp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = flights.groupby(['AIRLINE', 'ORG_AIR'])['CANCELLED'].sum()\n",
    "fg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_unstack = fg.unstack('ORG_AIR', fill_value=0)\n",
    "fg_unstack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.equals(fg_unstack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There's more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp2 = flights.pivot_table(index=['AIRLINE', 'MONTH'],\n",
    "                          columns=['ORG_AIR', 'CANCELLED'],\n",
    "                          values=['DEP_DELAY', 'DIST'],\n",
    "                          aggfunc=[np.mean, np.sum],\n",
    "                          fill_value=0)\n",
    "fp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.groupby(['AIRLINE', 'MONTH', 'ORG_AIR', 'CANCELLED'])['DEP_DELAY', 'DIST'] \\\n",
    "       .agg(['mean', 'sum']) \\\n",
    "       .unstack(['ORG_AIR', 'CANCELLED'], fill_value=0) \\\n",
    "       .swaplevel(0, 1, axis='columns') \\\n",
    "       .head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming axis levels for easy reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college = pd.read_csv('data/college.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = college.groupby(['STABBR', 'RELAFFIL'])['UGDS', 'SATMTMID'] \\\n",
    "            .agg(['count', 'min', 'max']).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = cg.rename_axis(['AGG_COLS', 'AGG_FUNCS'], axis='columns')\n",
    "cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg.stack('AGG_FUNCS').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg.stack('AGG_FUNCS').swaplevel('AGG_FUNCS', 'STABBR', axis='index').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg.stack('AGG_FUNCS') \\\n",
    "  .swaplevel('AGG_FUNCS', 'STABBR', axis='index') \\\n",
    "  .sort_index(level='RELAFFIL', axis='index') \\\n",
    "  .sort_index(level='AGG_COLS', axis='columns').head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg.stack('AGG_FUNCS').unstack(['RELAFFIL', 'STABBR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg.stack(['AGG_FUNCS', 'AGG_COLS']).head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There's more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg.rename_axis([None, None], axis='index').rename_axis([None, None], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidying when multiple variables are stored as column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightlifting = pd.read_csv('data/weightlifting_men.csv')\n",
    "weightlifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_melt = weightlifting.melt(id_vars='Weight Category', \n",
    "                             var_name='sex_age', \n",
    "                             value_name='Qual Total')\n",
    "wl_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_age = wl_melt['sex_age'].str.split(expand=True)\n",
    "sex_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_age.columns = ['Sex', 'Age Group']\n",
    "sex_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_age['Sex'] = sex_age['Sex'].str[0]\n",
    "sex_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_cat_total = wl_melt[['Weight Category', 'Qual Total']]\n",
    "wl_tidy = pd.concat([sex_age, wl_cat_total], axis='columns')\n",
    "wl_tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Weight Category', 'Qual Total']\n",
    "sex_age[cols] = wl_melt[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There's more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group = wl_melt.sex_age.str.extract('(\\d{2}[-+](?:\\d{2})?)', expand=False)\n",
    "sex = wl_melt.sex_age.str[0]\n",
    "new_cols = {'Sex':sex, \n",
    "            'Age Group': age_group}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_tidy2 = wl_melt.assign(**new_cols).drop('sex_age', axis='columns')\n",
    "wl_tidy2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_tidy2.sort_index(axis=1).equals(wl_tidy.sort_index(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidying when multiple variables are stored as column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspections = pd.read_csv('data/restaurant_inspections.csv', parse_dates=['Date'])\n",
    "inspections.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspections.pivot(index=['Name', 'Date'], columns='Info', values='Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspections.set_index(['Name','Date', 'Info']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspections.set_index(['Name','Date', 'Info']).unstack('Info').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insp_tidy = inspections.set_index(['Name','Date', 'Info']) \\\n",
    "                               .unstack('Info') \\\n",
    "                               .reset_index(col_level=-1)\n",
    "insp_tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insp_tidy.columns = insp_tidy.columns.droplevel(0).rename(None)\n",
    "insp_tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspections.set_index(['Name','Date', 'Info']) \\\n",
    "          .squeeze() \\\n",
    "          .unstack('Info') \\\n",
    "          .reset_index() \\\n",
    "          .rename_axis(None, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There's more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspections.pivot_table(index=['Name', 'Date'], \n",
    "                        columns='Info', \n",
    "                        values='Value', \n",
    "                        aggfunc='first') \\\n",
    "           .reset_index()\\\n",
    "           .rename_axis(None, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidying when two or more values are stored in the same cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.read_csv('data/texas_cities.csv')\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocations = cities.Geolocation.str.split(pat='. ', expand=True)\n",
    "geolocations.columns = ['latitude', 'latitude direction', 'longitude', 'longitude direction']\n",
    "geolocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocations = geolocations.astype({'latitude':'float', 'longitude':'float'})\n",
    "geolocations.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_tidy = pd.concat([cities['City'], geolocations], axis='columns')\n",
    "cities_tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([cities['City'], geolocations], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = geolocations.apply(pd.to_numeric, errors='ignore')\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There's more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.Geolocation.str.split(pat='° |, ', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.Geolocation.str.extract('([0-9.]+). (N|S), ([0-9.]+). (E|W)', expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidying when variables are stored in column names and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = pd.read_csv('data/sensors.csv')\n",
    "sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors.melt(id_vars=['Group', 'Property'], var_name='Year').head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors.melt(id_vars=['Group', 'Property'], var_name='Year') \\\n",
    "       .pivot_table(index=['Group', 'Year'], columns='Property', values='value') \\\n",
    "       .reset_index() \\\n",
    "       .rename_axis(None, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There's more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors.set_index(['Group', 'Property']) \\\n",
    "       .stack() \\\n",
    "       .unstack('Property') \\\n",
    "       .rename_axis(['Group', 'Year'], axis='index') \\\n",
    "       .rename_axis(None, axis='columns') \\\n",
    "       .reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidying when multiple observational units are stored in the same table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv('data/movie_altered.csv')\n",
    "movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.insert(0, 'id', np.arange(len(movie)))\n",
    "movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stubnames = ['director', 'director_fb_likes', 'actor', 'actor_fb_likes']\n",
    "movie_long = pd.wide_to_long(movie, \n",
    "                                 stubnames=stubnames, \n",
    "                                 i='id', \n",
    "                                 j='num', \n",
    "                                 sep='_').reset_index()\n",
    "movie_long['num'] = movie_long['num'].astype(int)\n",
    "movie_long.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_table = movie_long[['id','title', 'year', 'duration', 'rating']]\n",
    "director_table = movie_long[['id', 'director', 'num', 'director_fb_likes']]\n",
    "actor_table = movie_long[['id', 'actor', 'num', 'actor_fb_likes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_table.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_table.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_table.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_table = movie_table.drop_duplicates().reset_index(drop=True)\n",
    "director_table = director_table.dropna().reset_index(drop=True)\n",
    "actor_table = actor_table.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.memory_usage(deep=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_table.memory_usage(deep=True).sum() + \\\n",
    "director_table.memory_usage(deep=True).sum() + \\\n",
    "actor_table.memory_usage(deep=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_cat = pd.Categorical(director_table['director'])\n",
    "director_table.insert(1, 'director_id', director_cat.codes)\n",
    "\n",
    "actor_cat = pd.Categorical(actor_table['actor'])\n",
    "actor_table.insert(1, 'actor_id', actor_cat.codes)\n",
    "\n",
    "director_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_associative = director_table[['id', 'director_id', 'num']]\n",
    "dcols = ['director_id', 'director', 'director_fb_likes']\n",
    "director_unique = director_table[dcols].drop_duplicates().reset_index(drop=True)\n",
    "director_associative.head()                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_associative = actor_table[['id', 'actor_id', 'num']]\n",
    "acols = ['actor_id', 'actor', 'actor_fb_likes']\n",
    "actor_unique = actor_table[acols].drop_duplicates().reset_index(drop=True)\n",
    "actor_associative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_table.memory_usage(deep=True).sum() + \\\n",
    "director_associative.memory_usage(deep=True).sum() + \\\n",
    "director_unique.memory_usage(deep=True).sum() + \\\n",
    "actor_associative.memory_usage(deep=True).sum() + \\\n",
    "actor_unique.memory_usage(deep=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors = actor_associative.merge(actor_unique, on='actor_id') \\\n",
    "                          .drop('actor_id', 1) \\\n",
    "                          .pivot_table(index='id', columns='num', aggfunc='first')\n",
    "\n",
    "actors.columns = actors.columns.get_level_values(0) + '_' + \\\n",
    "                 actors.columns.get_level_values(1).astype(str)\n",
    "\n",
    "directors = director_associative.merge(director_unique, on='director_id') \\\n",
    "                          .drop('director_id', 1) \\\n",
    "                          .pivot_table(index='id', columns='num', aggfunc='first')\n",
    "\n",
    "directors.columns = directors.columns.get_level_values(0) + '_' + \\\n",
    "                    directors.columns.get_level_values(1).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie2 = movie_table.merge(directors.reset_index(), on='id', how='left') \\\n",
    "                    .merge(actors.reset_index(), on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.equals(movie2[movie.columns])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
