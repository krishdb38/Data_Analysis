{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This work book is from\n",
    "# https://dzone.com/articles/pyspark-join-explained-with-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName(\"joins_example\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-QV6GS5L:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>joins_example</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=joins_example>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "sc # The details about Spark can be Found from the sites\n",
    "# Click in Spark UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = [\n",
    "  {\n",
    "  'key' : 'abc',\n",
    "  'val11' : 1.1,\n",
    "  'val12' : 1.2\n",
    "  },\n",
    "  {\n",
    "  'key' : 'def',\n",
    "  'val11' : 3.0,\n",
    "  'val12' : 3.4\n",
    "  }\n",
    "]\n",
    "dataset2 = [\n",
    "  {\n",
    "  'key' : 'abc',\n",
    "  'val21' : 2.1,\n",
    "  'val22' : 2.2\n",
    "  },\n",
    "  {\n",
    "  'key' : 'xyz',\n",
    "  'val21' : 3.1,\n",
    "  'val22' : 3.2\n",
    "  }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\session.py:366: UserWarning: Using RDD of dict to inferSchema is deprecated. Use pyspark.sql.Row instead\n",
      "  warnings.warn(\"Using RDD of dict to inferSchema is deprecated. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1\n",
      "+---+-----+-----+\n",
      "|key|val11|val12|\n",
      "+---+-----+-----+\n",
      "|abc|  1.1|  1.2|\n",
      "|def|  3.0|  3.4|\n",
      "+---+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize(dataset1)\n",
    "df1 = spark.createDataFrame(rdd1)\n",
    "print(\"df1\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "|key|val21|val22|\n",
      "+---+-----+-----+\n",
      "|abc|  2.1|  2.2|\n",
      "|xyz|  3.1|  3.2|\n",
      "+---+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df2 = pd.DataFrame(dataset2) # Another Method\n",
    "df2 = spark.createDataFrame(df2)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The following kinds of joins are explained in this article\n",
    "- Inner Join\n",
    "- Outer Join\n",
    "- Left Join\n",
    "- Right Join\n",
    "- Left Semi Join\n",
    "- Left Anti Join\n",
    "- Left Anti Join\n",
    "- Inner Join with advance conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inner Join\n",
    "The inner join selects matching records from both of the dataframes. Match is performed on columns specified in the On Parameter. In this example both dataframes are joined when the column named key has same value, i.e. \"abc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
